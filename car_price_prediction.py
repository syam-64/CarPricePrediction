# -*- coding: utf-8 -*-
"""Car price prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GXSgw0FDKi_t8qLubMRB8pj6HdbRPQc4
"""

# Library untuk Dataframe
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
from datetime import datetime, timedelta

# Library untuk Data Visualisation
pd.options.display.float_format='{:.4f}'.format
plt.rcParams['figure.figsize'] = [8,8]
pd.set_option('display.max_columns', 500)
pd.set_option('display.max_colwidth', -1) 
sns.set(style='darkgrid')
import matplotlib.ticker as ticker
import matplotlib.ticker as plticker

# Library untuk Machine Learning
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.base import TransformerMixin
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import statsmodels.api as sm
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.metrics import r2_score

# Masukkan file

path = "/content/CarPrice_Assignment.csv"
file = path + 'CarPrice_Assignment.csv'
file1 = "/content/Data Dictionary - carprices.xlsx"

df_auto = pd.read_csv(path)

df_auto.head()

df_stru = pd.read_excel(file1)
df_stru.head(2)

# shape of the data
df_auto.shape

# information of the data
df_auto.info()

df_auto.describe()

df_auto = df_auto.drop('car_ID',axis=1)

# Mengkalkulasikan Value yang hilang % kontribusinya pada Dataframe

df_null = df_auto.isna().mean().round(4) * 100

df_null.sort_values(ascending=False).head()

# Datatypes
df_auto.dtypes

# Analisa outlier

outliers = ['price']
plt.rcParams['figure.figsize'] = [8,8]
sns.boxplot(data=df_auto[outliers], orient="v", palette="Set1" ,whis=1.5,saturation=1, width=0.7)
plt.title("Outliers Variable Distribution", fontsize = 14, fontweight = 'bold')
plt.ylabel("Price Range", fontweight = 'bold')
plt.xlabel("Continuous Variable", fontweight = 'bold')
df_auto.shape

# Mencari Perusahaan Mobil / Brand Mobil yang memiliki nama bersifat 'Unique'

df_auto['CarName'].unique()

# Merapikan nama-nama Brand Mobil yang masih memiliki typo

df_auto['CarName'] = df_auto['CarName'].replace({'maxda': 'mazda', 'nissan': 'Nissan', 'porcshce': 'porsche', 'toyouta': 'toyota', 
                            'vokswagen': 'volkswagen', 'vw': 'volkswagen'})

# Mengubah tipe data dari 'symboling' menjadi string di mana sebelumnya merupakan integer

df_auto['symboling'] = df_auto['symboling'].astype(str)

# Mengecek apakah ada duplikasi pada Dataframe df_auto

df_auto.loc[df_auto.duplicated()]

# Memisahkan Kolom (termasuk Variabel) yang bertipe data Numerikal (integer,float,dst.) dan Kategorikal (string/object)
# df_cat = df_categorical = Dataframe Categorical (Dataframe yang hanya memiliki kolom bertipedata String)
# df_num = df_numerical = Dataframe Numerical (Dataframe yang hanya memiliki kolom bertipedata Numerikal seperti integer,float,dst.)

cat_col = df_auto.select_dtypes(include=['object']).columns
num_col = df_auto.select_dtypes(exclude=['object']).columns
df_cat = df_auto[cat_col]
df_num = df_auto[num_col]

# Menampilkan nama-nama Brand Mobil beserta jumlah total dari berapa tipe mobil yang diproduksi yang tersedia pada Dataframe

plt.rcParams['figure.figsize'] = [15,8]
ax=df_auto['CarName'].value_counts().plot(kind='bar',stacked=True, colormap = 'Set1')
ax.title.set_text('CarName')
plt.xlabel("Names of the Car",fontweight = 'bold')
plt.ylabel("Count of Cars",fontweight = 'bold')

# Menampilkan distribusi harga mobil yang ada pada Dataframe

plt.figure(figsize=(8,8))

plt.title('Car Price Distribution Plot')
sns.distplot(df_auto['price'])

# Visualisasi Variabel Numerikal

# Mencari tahu korelasi antar masing-masing Variabel Numerik dengan 1 Variabel Numerik lainnya yang ada pada Dataframe

# Fokus hanya pada korelasi antara tiap-tiap Variabel Numerik lainnya dengan Variabel Numerik 'price' karena kita hanya ingin mencari tahu apakah tiap-tiap
# Variabel Numerik lainnya tersebut memiliki pengaruh pada 'price' baik itu berupa dampak positif maupun negatif yang dapat menyebabkan 'price' naik ataupun
# turun

ax = sns.pairplot(df_auto[num_col])

# Visualisasi Variabel Kategorikal

# Visualisasi ditampilkan dalam grafik Boxplot untuk menunjukkan korelasi antara tiap-tiap variabel kategorikal dan price

plt.figure(figsize=(20, 15))
plt.subplot(3,3,1)
sns.boxplot(x = 'doornumber', y = 'price', data = df_auto)
plt.subplot(3,3,2)
sns.boxplot(x = 'fueltype', y = 'price', data = df_auto)
plt.subplot(3,3,3)
sns.boxplot(x = 'aspiration', y = 'price', data = df_auto)
plt.subplot(3,3,4)
sns.boxplot(x = 'carbody', y = 'price', data = df_auto)
plt.subplot(3,3,5)
sns.boxplot(x = 'enginelocation', y = 'price', data = df_auto)
plt.subplot(3,3,6)
sns.boxplot(x = 'drivewheel', y = 'price', data = df_auto)
plt.subplot(3,3,7)
sns.boxplot(x = 'enginetype', y = 'price', data = df_auto)
plt.subplot(3,3,8)
sns.boxplot(x = 'cylindernumber', y = 'price', data = df_auto)
plt.subplot(3,3,9)
sns.boxplot(x = 'fuelsystem', y = 'price', data = df_auto)
plt.show()

# # Mencari tahu tipe-tipe apa saja yang paling banyak dan paling sedikit digunakan untuk produksi tiap mobil dan seberapa banyak jumlah tiap mobil
# # yang diproduksi dengan masing-masing tipe tersebut

plt.figure(figsize=(25, 6))

plt.subplot(1,3,1)
plt1 = df_auto['enginesize'].value_counts().plot(kind='bar')
plt.title('size of engine')
plt1.set(xlabel = 'size of engine', ylabel='Frequency of size of engine')

plt.subplot(1,3,2)
plt1 = df_auto['wheelbase'].value_counts().plot(kind='bar')
plt.title('stroke')
plt1.set(xlabel = 'stroke', ylabel='Frequency of stroke')

plt.subplot(1,3,3)
plt1 = df_auto['curbweight'].value_counts().plot(kind='bar')
plt.title('carheight')
plt1.set(xlabel = 'carheight', ylabel='carheight')

# Hubungan antara 'fuelsystem' dan 'price' dengan warna dasar / hue dari 'fueltype' untuk sekaligus mengetahui bahan bakar apa yang digunakan dalam masing-
# masing mobil dengan 'fuelsystem' tertentu

plt.figure(figsize = (10, 6))
sns.boxplot(x = 'fuelsystem', y = 'price', hue = 'fueltype', data = df_auto)
plt.show()

# Hubungan antara 'carbody' dan 'price' dengan warna dasar / hue dari 'enginelocation' untuk sekaligus mengetahui tipe 'enginelocation' apa yang digunakan dalam
# masing-masing mobil dengan 'carbody' tertentu

plt.figure(figsize = (10, 6))
sns.boxplot(x = 'carbody', y = 'price', hue = 'enginelocation', data = df_auto)
plt.show()

# Hubungan antara 'cylindernumber' dan 'price' dengan warna dasar / hue dari 'fueltype' untuk sekaligus mengetahui tipe 'fueltype' apa yang digunakan dalam
# masing-masing mobil dengan 'cylindernumber' tertentu

plt.figure(figsize = (10, 6))
sns.boxplot(x = 'cylindernumber', y = 'price', hue = 'fueltype', data = df_auto)
plt.show()

# Harga mobil rata-rata untuk tiap Brand Mobil

plt.figure(figsize=(20, 6))

df_autox = pd.DataFrame(df_auto.groupby(['CarName'])['price'].mean().sort_values(ascending = False))
df_autox.plot.bar()
plt.title('Car Company Name vs Average Price')
plt.show()

plt.figure(figsize=(20, 6))

df_autoy = pd.DataFrame(df_auto.groupby(['carbody'])['price'].mean().sort_values(ascending = False))
df_autoy.plot.bar()
plt.title('Car Company Name vs Average Price')
plt.show()

# Melakukan 'Binning' berdasarkan data harga rata-rata untuk mengelompokkan tipe-tipe mobil pada masing-masing Brand Mobil yang di mana terdapat 3 kelas
# mobil berdasarkan harganya, yaitu 'Budget_Friendly', 'Medium_Range', 'TopNotch_Cars' yang dapat diartikan sebagai 'Harga yang Ramah', 'Harga Cukup Mahal', dan
# 'Harga Mahal / Mobil Kelas Atas'

df_auto['price'] = df_auto['price'].astype('int')
df_auto_temp = df_auto.copy()
t = df_auto_temp.groupby(['CarName'])['price'].mean()
df_auto_temp = df_auto_temp.merge(t.reset_index(), how='left',on='CarName')
bins = [0,10000,20000,40000]
label =['Budget_Friendly','Medium_Range','TopNotch_Cars']
df_auto['Cars_Category'] = pd.cut(df_auto_temp['price_y'],bins,right=False,labels=label)
df_auto.head(20)

sig_col = ['price','Cars_Category','enginetype','fueltype', 'aspiration','carbody','cylindernumber', 'drivewheel',
            'wheelbase','curbweight', 'enginesize', 'boreratio','horsepower', 
                    'citympg','highwaympg', 'carlength','carwidth']

df_auto = df_auto[sig_col]

"""
PERSIAPAN DATA UNTUK PREDIKSI HARGA
"""

# Membuat variabel asal yang kita beri nama 'dummies' untuk menyimpan variabel yang bersifat Kategorikal pada variabel carbody yang terdapat 5 variabel,
# variabel Kategorikal ini kemudian akan kita ubah menjadi variabel Numerikal

sig_cat_col = ['Cars_Category','fueltype','aspiration','carbody','drivewheel','enginetype','cylindernumber']

dummies = pd.get_dummies(df_auto[sig_cat_col])
dummies.shape

dummies = pd.get_dummies(df_auto[sig_cat_col], drop_first = True)
dummies.shape

# Masukkan variabel 'dummies' ke dalam Dataframe original

df_auto = pd.concat([df_auto, dummies], axis = 1)

# Hapus variabel Kategorikal original karena digantikan dengan variabel 'dummies'

df_auto.drop( sig_cat_col, axis = 1, inplace = True)
df_auto.shape

"""
PEMISAHAN DATAFRAME MENJADI TRAINING DAN TESTING
"""

# Dasar dari metode Regresi adalah melakukan pemisahan data menjadi training dan testing (train-test split)
# Dataframe (df_auto) akan dibagi dengan rasio 70/30

df_auto

np.random.seed(0)
df_train, df_test = train_test_split(df_auto, train_size = 0.7, test_size = 0.3, random_state = 100)

df_train.head()

# Melakukan 'Rescaling' agar variabel-variabel yang ada memiliki skala yang sebanding

scaler = preprocessing.StandardScaler()

sig_num_col = ['wheelbase','carlength','carwidth','curbweight','enginesize','boreratio','horsepower','citympg','highwaympg','price']

# Menerapkan function scaler() pada semua kolom, kecuali variabel 'dummies'

import warnings
warnings.filterwarnings("ignore")

df_train[sig_num_col] = scaler.fit_transform(df_train[sig_num_col])

df_train.head()

# Memeriksa korelasi koefisien-koefisien untuk melihat variabel-variabel yang paling berkorelasi

plt.figure(figsize = (20, 20))
sns.heatmap(df_train.corr(), cmap="RdYlGn")
plt.show()

# Pembuatan scatterplot untuk melihat hubungan beberapa variabel dengan price

col = ['highwaympg','citympg','horsepower','enginesize','curbweight','carwidth']

# Bentuk Scatter Plot dari variabel independen vs variabel dependen

fig,axes = plt.subplots(2,3,figsize=(18,15))
for seg,col in enumerate(col):
    x,y = seg//3,seg%3
    an=sns.scatterplot(x=col, y='price' ,data=df_auto, ax=axes[x,y])
    plt.setp(an.get_xticklabels(), rotation=45)
   
plt.subplots_adjust(hspace=0.5)

# Pemisahan menjadi set X dan Y untuk pembuatan model

y_train = df_train.pop('price')
X_train = df_train

"""
PEMBUATAN MODEL LINEAR
"""

X_train_1 = X_train['horsepower']

X_train_1c = sm.add_constant(X_train_1)

lr_1 = sm.OLS(y_train, X_train_1c).fit()

lr_1.params

# Visualisasi data dengan scatter plot dan garis regresi yang fit

plt.scatter(X_train_1c.iloc[:, 1], y_train)
plt.plot(X_train_1c.iloc[:, 1], 0.8062*X_train_1c.iloc[:, 1], 'r')
plt.show()

print(lr_1.summary())

X_train_2 = X_train[['horsepower', 'curbweight']]

# Tambah konstanta
X_train_2c = sm.add_constant(X_train_2)

# Membuat model kedua yang fit
lr_2 = sm.OLS(y_train, X_train_2c).fit()

lr_2.params

print(lr_2.summary())

X_train_3 = X_train[['horsepower', 'curbweight', 'enginesize']]

# Tambah konstanta
X_train_3c = sm.add_constant(X_train_3)

# Membuat model ketiga yang fit
lr_3 = sm.OLS(y_train, X_train_3c).fit()

lr_3.params

print(lr_3.summary())

# Menjalankan RFE dengan hasil output dari variabel yang sama dengan 15

lm = LinearRegression()
lm.fit(X_train, y_train)

rfe = RFE(lm)             
rfe = rfe.fit(X_train, y_train)

list(zip(X_train.columns,rfe.support_,rfe.ranking_))

# Memilih variabel yang mendukung

col_sup = X_train.columns[rfe.support_]
col_sup

# Membuat dataframe X_train dengan variabel terpilih RFE

X_train_rfe = X_train[col_sup]

# Menambahkan sebuah variabel konstan dan membangun sebuah model pertama yang fit
import statsmodels.api as sm  
X_train_rfec = sm.add_constant(X_train_rfe)
lm_rfe = sm.OLS(y_train,X_train_rfec).fit()

#Summary of linear model
print(lm_rfe.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe1 = X_train_rfe.drop('cylindernumber_twelve', 1,)

# Adding a constant variable and Build a second fitted model

X_train_rfe1c = sm.add_constant(X_train_rfe1)
lm_rfe1 = sm.OLS(y_train, X_train_rfe1c).fit()

#Summary of linear model
print(lm_rfe1.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe1.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe1.values, i) for i in range(X_train_rfe1.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe2 = X_train_rfe1.drop('cylindernumber_six', 1,)

# Adding a constant variable and Build a third fitted model

X_train_rfe2c = sm.add_constant(X_train_rfe2)
lm_rfe2 = sm.OLS(y_train, X_train_rfe2c).fit()

#Summary of linear model
print(lm_rfe2.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe2.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe2.values, i) for i in range(X_train_rfe2.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe3 = X_train_rfe2.drop('carbody_hardtop', 1,)

# Adding a constant variable and Build a fourth fitted model
X_train_rfe3c = sm.add_constant(X_train_rfe3)
lm_rfe3 = sm.OLS(y_train, X_train_rfe3c).fit()

#Summary of linear model
print(lm_rfe3.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe3.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe3.values, i) for i in range(X_train_rfe3.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe4 = X_train_rfe3.drop('enginetype_ohc', 1,)

# Adding a constant variable and Build a fifth fitted model
X_train_rfe4c = sm.add_constant(X_train_rfe4)
lm_rfe4 = sm.OLS(y_train, X_train_rfe4c).fit()

#Summary of linear model
print(lm_rfe4.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe4.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe4.values, i) for i in range(X_train_rfe4.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe5 = X_train_rfe4.drop('cylindernumber_five', 1,)

# Adding a constant variable and Build a sixth fitted model
X_train_rfe5c = sm.add_constant(X_train_rfe5)
lm_rfe5 = sm.OLS(y_train, X_train_rfe5c).fit()

#Summary of linear model
print(lm_rfe5.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe5.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe5.values, i) for i in range(X_train_rfe5.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe6 = X_train_rfe5.drop('enginetype_dohcv', 1,)

# Adding a constant variable and Build a sixth fitted model
X_train_rfe6c = sm.add_constant(X_train_rfe6)
lm_rfe6 = sm.OLS(y_train, X_train_rfe6c).fit()

#Summary of linear model
print(lm_rfe6.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe6.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe6.values, i) for i in range(X_train_rfe6.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe7 = X_train_rfe6.drop('enginetype_l', 1,)

# Adding a constant variable and Build a sixth fitted model
X_train_rfe7c = sm.add_constant(X_train_rfe7)
lm_rfe7 = sm.OLS(y_train, X_train_rfe7c).fit()

#Summary of linear model
print(lm_rfe7.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe7.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe7.values, i) for i in range(X_train_rfe7.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe8 = X_train_rfe7.drop('cylindernumber_four', 1,)

# Adding a constant variable and Build a sixth fitted model
X_train_rfe8c = sm.add_constant(X_train_rfe8)
lm_rfe8 = sm.OLS(y_train, X_train_rfe8c).fit()

#Summary of linear model
print(lm_rfe8.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe8.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe8.values, i) for i in range(X_train_rfe8.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe9 = X_train_rfe8.drop('carbody_sedan', 1,)

# Adding a constant variable and Build a sixth fitted model
X_train_rfe9c = sm.add_constant(X_train_rfe9)
lm_rfe9 = sm.OLS(y_train, X_train_rfe9c).fit()

#Summary of linear model
print(lm_rfe9.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe9.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe9.values, i) for i in range(X_train_rfe9.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Dropping highly correlated variables and insignificant variables

X_train_rfe10 = X_train_rfe9.drop('carbody_wagon', 1,)

# Adding a constant variable and Build a sixth fitted model
X_train_rfe10c = sm.add_constant(X_train_rfe10)
lm_rfe10 = sm.OLS(y_train, X_train_rfe10c).fit()

#Summary of linear model
print(lm_rfe10.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe10.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe10.values, i) for i in range(X_train_rfe10.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

# Predicting the price of training set.
y_train_price = lm_rfe10.predict(X_train_rfe10c)

# Plot the histogram of the error terms
fig = plt.figure()
sns.distplot((y_train - y_train_price), bins = 20)
fig.suptitle('Error Terms Analysis', fontsize = 20)                   
plt.xlabel('Errors', fontsize = 18)

import warnings
warnings.filterwarnings("ignore")

df_test[sig_num_col] = scaler.transform(df_test[sig_num_col])
df_test.shape

y_test = df_test.pop('price')
X_test = df_test

# Adding constant
X_test_1 = sm.add_constant(X_test)

X_test_new = X_test_1[X_train_rfe10c.columns]

# Making predictions using the final model
y_pred = lm_rfe10.predict(X_test_new)

# Plotting y_test and y_pred to understand the spread.
fig = plt.figure()
plt.scatter(y_test,y_pred)
fig.suptitle('y_test vs y_pred', fontsize=20)   
plt.xlabel('y_test ', fontsize=18)                       
plt.ylabel('y_pred', fontsize=16)

r2_score(y_test, y_pred)

# Predicting the price of training set.
y_train_price2 = lm_rfe8.predict(X_train_rfe8c)

# Plot the histogram of the error terms
fig = plt.figure()
sns.distplot((y_train - y_train_price2), bins = 20)
fig.suptitle('Error Terms Analysis', fontsize = 20)                   
plt.xlabel('Errors', fontsize = 18)

X_test_2 = X_test_1[X_train_rfe8c.columns]

# Making predictions using the final model
y_pred2 = lm_rfe8.predict(X_test_2)

# Plotting y_test and y_pred to understand the spread.
fig = plt.figure()
plt.scatter(y_test,y_pred2)
fig.suptitle('y_test vs y_pred2', fontsize=20)   
plt.xlabel('y_test ', fontsize=18)                       
plt.ylabel('y_pred2', fontsize=16)

r2_score(y_test, y_pred2)